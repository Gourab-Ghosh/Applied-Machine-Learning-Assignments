{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignore Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Important Variables and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER  = os.path.abspath(\"./data\")\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "TEST_FILE = \"test.csv\"\n",
    "VAL_FILE = \"validation.csv\"\n",
    "\n",
    "MODEL_PARAMETERS = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": 1.0,  # Inverse of regularization strength\n",
    "        \"solver\": \"lbfgs\",  # Algorithm to use in the optimization problem\n",
    "        \"max_iter\": 1000,  # Maximum number of iterations for optimization\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": 100,  # Number of trees in the forest\n",
    "        \"max_depth\": None,  # Maximum depth of the tree\n",
    "        \"min_samples_split\": 2,  # Minimum number of samples required to split an internal node\n",
    "        \"min_samples_leaf\": 1,  # Minimum number of samples required to be at a leaf node\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        \"n_estimators\": 100,  # Number of boosting stages\n",
    "        \"learning_rate\": 0.1,  # Learning rate shrinks the contribution of each tree\n",
    "        \"max_depth\": 3,  # Maximum depth of the individual estimators\n",
    "        \"min_samples_split\": 2,  # Minimum number of samples required to split an internal node\n",
    "        \"min_samples_leaf\": 1,  # Minimum number of samples required to be at a leaf node\n",
    "        \"max_features\": None,  # Number of features to consider when looking for the best split\n",
    "        \"subsample\": 1.0,  # Fraction of samples used for fitting the individual base learners\n",
    "    },\n",
    "}\n",
    "\n",
    "MODELS = [\n",
    "    (\"Logistic Regression\", LogisticRegression(**MODEL_PARAMETERS[\"Logistic Regression\"])),\n",
    "    (\"Random Forest\", RandomForestClassifier(**MODEL_PARAMETERS[\"Random Forest\"])),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier(**MODEL_PARAMETERS[\"Gradient Boosting\"])),\n",
    "]\n",
    "\n",
    "BEST_MODEL_NAME = None\n",
    "BEST_MODEL_AUCPR = -float(\"inf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Important Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_file, test_file, val_file):\n",
    "    train_df = pd.read_csv(os.path.join(DATA_FOLDER, train_file))\n",
    "    test_df = pd.read_csv(os.path.join(DATA_FOLDER, test_file))\n",
    "    val_df = pd.read_csv(os.path.join(DATA_FOLDER, val_file))\n",
    "    return train_df, test_df, val_df\n",
    "\n",
    "def train_evaluate_and_save_model(model_name, model, X_train, y_train, X_val, y_val):\n",
    "    print(f\"Training, Evaluating and Registering Model: {model_name}\")\n",
    "    model_parameters = MODEL_PARAMETERS[model_name]\n",
    "    print(f\"\\nModel Parameters:\\n{json.dumps(model_parameters, indent = 4)}\\n\")\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_val, y_pred_proba)\n",
    "        aucpr = auc(recall, precision)\n",
    "        mlflow.log_param(\"model_name\", model_name)\n",
    "        mlflow.log_params(model_parameters)\n",
    "        mlflow.log_metric(\"AUCPR\", aucpr)\n",
    "        mlflow.sklearn.log_model(model, model_name)\n",
    "\n",
    "    print(f\"Registered Model: {model_name}\")\n",
    "\n",
    "def load_and_evaluate_model(model_name, X_val_tfidf, y_val):\n",
    "    global BEST_MODEL_NAME, BEST_MODEL_AUCPR\n",
    "    runs = mlflow.search_runs(filter_string=f\"params.model_name = \\\"{model_name}\\\"\")\n",
    "    if not runs.empty:\n",
    "        run_id = runs.iloc[0].run_id\n",
    "        model_uri = f\"runs:/{run_id}/{model_name}\"\n",
    "        loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "        y_pred_proba = loaded_model.predict_proba(X_val_tfidf)[:, 1]\n",
    "        precision, recall, _ = precision_recall_curve(y_val, y_pred_proba)\n",
    "        aucpr = auc(recall, precision)\n",
    "        if aucpr > BEST_MODEL_AUCPR:\n",
    "            BEST_MODEL_NAME = model_name\n",
    "            BEST_MODEL_AUCPR = aucpr\n",
    "        print(f\"{model_name} AUCPR: {aucpr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, val_df = load_data(TRAIN_FILE, TEST_FILE, VAL_FILE)\n",
    "\n",
    "X_train, y_train = train_df[\"text\"], train_df[\"spam\"]\n",
    "X_test, y_test = test_df[\"text\"], test_df[\"spam\"]\n",
    "X_val, y_val = val_df[\"text\"], val_df[\"spam\"]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "\n",
    "model_parameters = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluating and Registering Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, Evaluating and Registering Model: Logistic Regression\n",
      "\n",
      "Model Parameters:\n",
      "{\n",
      "    \"C\": 1.0,\n",
      "    \"solver\": \"lbfgs\",\n",
      "    \"max_iter\": 1000\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered Model: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_and_save_model(*MODELS[0], X_train_tfidf, y_train, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluating and Registering Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, Evaluating and Registering Model: Random Forest\n",
      "\n",
      "Model Parameters:\n",
      "{\n",
      "    \"n_estimators\": 100,\n",
      "    \"max_depth\": null,\n",
      "    \"min_samples_split\": 2,\n",
      "    \"min_samples_leaf\": 1\n",
      "}\n",
      "\n",
      "Registered Model: Random Forest\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_and_save_model(*MODELS[1], X_train_tfidf, y_train, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training, Evaluating and Registering Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training, Evaluating and Registering Model: Gradient Boosting\n",
      "\n",
      "Model Parameters:\n",
      "{\n",
      "    \"n_estimators\": 100,\n",
      "    \"learning_rate\": 0.1,\n",
      "    \"max_depth\": 3,\n",
      "    \"min_samples_split\": 2,\n",
      "    \"min_samples_leaf\": 1,\n",
      "    \"max_features\": null,\n",
      "    \"subsample\": 1.0\n",
      "}\n",
      "\n",
      "Registered Model: Gradient Boosting\n"
     ]
    }
   ],
   "source": [
    "train_evaluate_and_save_model(*MODELS[2], X_train_tfidf, y_train, X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression AUCPR: 0.9988594292001929\n"
     ]
    }
   ],
   "source": [
    "load_and_evaluate_model(MODELS[0][0], X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest AUCPR: 0.995232000963588\n"
     ]
    }
   ],
   "source": [
    "load_and_evaluate_model(MODELS[1][0], X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation for Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting AUCPR: 0.9892071201001098\n"
     ]
    }
   ],
   "source": [
    "load_and_evaluate_model(MODELS[2][0], X_val_tfidf, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running MLFlow UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-21 15:48:34 +0530] [122118] [INFO] Starting gunicorn 21.2.0\n",
      "[2024-02-21 15:48:34 +0530] [122118] [INFO] Listening at: http://127.0.0.1:5000 (122118)\n",
      "[2024-02-21 15:48:34 +0530] [122118] [INFO] Using worker: sync\n",
      "[2024-02-21 15:48:34 +0530] [122128] [INFO] Booting worker with pid: 122128\n",
      "[2024-02-21 15:48:34 +0530] [122129] [INFO] Booting worker with pid: 122129\n",
      "[2024-02-21 15:48:34 +0530] [122130] [INFO] Booting worker with pid: 122130\n",
      "[2024-02-21 15:48:35 +0530] [122131] [INFO] Booting worker with pid: 122131\n",
      "^C\n",
      "[2024-02-21 15:49:41 +0530] [122118] [INFO] Handling signal: int\n",
      "[2024-02-21 15:49:41 +0530] [122130] [INFO] Worker exiting (pid: 122130)\n",
      "[2024-02-21 15:49:41 +0530] [122129] [INFO] Worker exiting (pid: 122129)\n",
      "[2024-02-21 15:49:41 +0530] [122131] [INFO] Worker exiting (pid: 122131)\n",
      "[2024-02-21 15:49:41 +0530] [122128] [INFO] Worker exiting (pid: 122128)\n"
     ]
    }
   ],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model by AUCPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Logistic Regression\n",
      "Best Model AUCPR: 0.9988594292001929\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Model: {BEST_MODEL_NAME}\")\n",
    "print(f\"Best Model AUCPR: {BEST_MODEL_AUCPR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
